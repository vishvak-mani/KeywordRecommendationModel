{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/boudinfl/pke.git\n",
      "  Cloning https://github.com/boudinfl/pke.git to /private/var/folders/06/tbj250m56w5bpywjm_0xr3vm0000gn/T/pip-req-build-4pqhwz2y\n",
      "  Running command git clone -q https://github.com/boudinfl/pke.git /private/var/folders/06/tbj250m56w5bpywjm_0xr3vm0000gn/T/pip-req-build-4pqhwz2y\n",
      "Requirement already satisfied: nltk in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from pke==1.8.1) (3.4.5)\n",
      "Requirement already satisfied: networkx in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from pke==1.8.1) (2.4)\n",
      "Requirement already satisfied: numpy in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from pke==1.8.1) (1.18.1)\n",
      "Requirement already satisfied: scipy in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from pke==1.8.1) (1.4.1)\n",
      "Requirement already satisfied: spacy in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from pke==1.8.1) (2.0.12)\n",
      "Requirement already satisfied: six in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from pke==1.8.1) (1.14.0)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
      "\u001b[K     |████████████████████████████████| 238 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from pke==1.8.1) (0.18.2)\n",
      "Requirement already satisfied: joblib in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from pke==1.8.1) (0.14.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from networkx->pke==1.8.1) (4.4.2)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from spacy->pke==1.8.1) (0.28.0)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from spacy->pke==1.8.1) (1.31.2)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from spacy->pke==1.8.1) (1.0.1)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.3 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from spacy->pke==1.8.1) (6.10.3)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from spacy->pke==1.8.1) (0.9.6)\n",
      "Requirement already satisfied: ujson>=1.35 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from spacy->pke==1.8.1) (1.35)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from spacy->pke==1.8.1) (0.2.9)\n",
      "Collecting regex==2017.4.5\n",
      "  Downloading regex-2017.04.05.tar.gz (601 kB)\n",
      "\u001b[K     |████████████████████████████████| 601 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from spacy->pke==1.8.1) (2.23.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from sklearn->pke==1.8.1) (0.22.1)\n",
      "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from thinc<6.11.0,>=6.10.3->spacy->pke==1.8.1) (0.5.6)\n",
      "Requirement already satisfied: msgpack-numpy<1.0.0,>=0.4.1 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from thinc<6.11.0,>=6.10.3->spacy->pke==1.8.1) (0.4.4.3)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from thinc<6.11.0,>=6.10.3->spacy->pke==1.8.1) (0.9.0.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from thinc<6.11.0,>=6.10.3->spacy->pke==1.8.1) (1.10.11)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from thinc<6.11.0,>=6.10.3->spacy->pke==1.8.1) (4.44.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2.9)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /Users/mansirathod/anaconda3/lib/python3.7/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy->pke==1.8.1) (0.10.0)\n",
      "Building wheels for collected packages: pke, sklearn, regex\n",
      "  Building wheel for pke (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pke: filename=pke-1.8.1-py3-none-any.whl size=8759615 sha256=517e36d4a106e4269f4aa17728e33d660b4540a34f03c51c6896d108f2e51042\n",
      "  Stored in directory: /private/var/folders/06/tbj250m56w5bpywjm_0xr3vm0000gn/T/pip-ephem-wheel-cache-4_06b3gg/wheels/fa/b3/09/612ee93bf3ee4164bcd5783e742942cdfc892a86039d3e0a33\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=41c1b06dd0d4017d284f5526b25ca94df4c4ff8eb51383e9d7e11b9cf643cb8f\n",
      "  Stored in directory: /Users/mansirathod/Library/Caches/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for regex: filename=regex-2017.4.5-cp37-cp37m-macosx_10_7_x86_64.whl size=266909 sha256=02f3e4df6b19ccf2304e8fc09a7876ecf9ed05155d43e1ab1408ba42affd9a8c\n",
      "  Stored in directory: /Users/mansirathod/Library/Caches/pip/wheels/3d/e8/a5/d4894e7ef29935f75c6074409ce8ca80a0271f0ce2a30da5d3\n",
      "Successfully built pke sklearn regex\n",
      "Installing collected packages: sklearn, unidecode, pke, regex\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2018.7.11\n",
      "    Uninstalling regex-2018.7.11:\n",
      "      Successfully uninstalled regex-2018.7.11\n",
      "Successfully installed pke-1.8.1 regex-2017.4.5 sklearn-0.0 unidecode-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/boudinfl/pke.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-35fa56cdd012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpke\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtextract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textract'"
     ]
    }
   ],
   "source": [
    "import pke\n",
    "from nltk.corpus import stopwords\n",
    "import textract\n",
    "import PyPDF2\n",
    "import os\n",
    "import argparse\n",
    "import re\n",
    "from tika  import parser as tika_parser\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import ssl\n",
    "import spacy\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('stopwords')\n",
    "nltk.download('universal_tagset')\n",
    "spacy.download('en')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "from rake_nltk import Rake, Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lobal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_list_stop_words = []\n",
    "db_investors_by_topic = {}\n",
    "db_keyword_by_topic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintHelp():\n",
    "    print(\"Help\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_by_tika(filepath):\n",
    "    raw = tika_parser.from_file(filepath)\n",
    "    return(raw['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_by_textract(filepath):\n",
    "    resume_extract_text = textract.process(filepath, encoding='ascii')\n",
    "    return(str(resume_extract_text.decode(\"ASCII\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_yake_pke(filename, text):\n",
    "    text = re.sub('[^a-zA-Z0-9|^\\-]', ' ', text)\n",
    "\n",
    "    # Remove words with digits\n",
    "    text = re.sub(\"\\S*\\d\\S*\", \"\", text).strip()\n",
    "\n",
    "    # Remove empty hyphens\n",
    "    text = re.sub(' - ', ' ', text)\n",
    "    extractor = pke.unsupervised.YAKE()\n",
    "    extractor.load_document(input=text,\n",
    "                            language='en',\n",
    "                            normalization=None)\n",
    "    stoplist = stopwords.words('english')\n",
    "    stoplist += custom_list_stop_words\n",
    "    extractor.candidate_selection(n=2, stoplist=stoplist)\n",
    "    window = 2\n",
    "    use_stems = True # use stems instead of words for weighting\n",
    "    extractor.candidate_weighting(window=window,\n",
    "                              stoplist=stoplist,\n",
    "                              use_stems=use_stems)\n",
    "    threshold = 0.7\n",
    "    keyphrases = extractor.get_n_best(n=20, threshold=threshold)\n",
    "    return keyphrases\n",
    "    for kw in keyphrases:\n",
    "        print(kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_files_from_folder(input_folder):\n",
    "    list_of_files = []\n",
    "    for dirpath, _, filenames in os.walk(input_folder):\n",
    "        for f in filenames:\n",
    "            if f.endswith(\".pdf\") or f.endswith(\".doc\") or f.endswith(\".docx\") or f.endswith(\".txt\") or f.endswith(\".csv\"):\n",
    "                list_of_files.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "    return list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfStopWords(stopwords_dir):\n",
    "    global custom_list_stop_words\n",
    "    list_files = get_list_of_files_from_folder(stopwords_dir)\n",
    "    if len(list_files) == 0:\n",
    "        return\n",
    "    for file_path in list_files:\n",
    "        filename_w_ext = os.path.basename(file_path)\n",
    "        file1 = open(file_path, 'r')\n",
    "        lines = file1.readlines()\n",
    "        for line in lines:\n",
    "            custom_list_stop_words.append(line.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SuggestInvestors(input_folder, stopwords_dir):\n",
    "    global db_keyword_by_topic\n",
    "    global db_investors_by_topic\n",
    "    list_files = get_list_of_files_from_folder(input_folder)\n",
    "    if len(list_files) == 0:\n",
    "        print(\"No Files found in input folder \" + input_folder + \"\\n Exiting program\")\n",
    "        PrintHelp()\n",
    "        return\n",
    "    getListOfStopWords(stopwords_dir)\n",
    "    for file_path in list_files:\n",
    "        filename_w_ext = os.path.basename(file_path)\n",
    "        keywords = []\n",
    "        if filename_w_ext.endswith(\".pdf\"):\n",
    "            text = get_text_by_tika(file_path)\n",
    "        else:\n",
    "            text = get_text_by_textract(file_path)\n",
    "        keywords = extract_keywords_yake_pke(filename_w_ext, text)\n",
    "        keywords_score = {}\n",
    "        for kw in keywords:\n",
    "            keyword = str(kw[0])\n",
    "            if (keyword in db_keyword_by_topic):\n",
    "                if keyword not in keywords_score:\n",
    "                    keywords_score[db_keyword_by_topic[keyword]] = 1\n",
    "                else:\n",
    "                    keywords_score[db_keyword_by_topic[keyword]] += 1\n",
    "        reverse_sorted = sorted(keywords_score.items(), key=lambda x: (-x[1], x[0]))\n",
    "        key_industry = list(reverse_sorted[0])\n",
    "        print(\"Keywords for - \" + filename_w_ext)\n",
    "        print(keywords)\n",
    "        print(\"Key Industry : \" + key_industry[0])\n",
    "        if (key_industry[0] in db_investors_by_topic):\n",
    "            print (\"Suggested Investors :\")\n",
    "            investors = db_investors_by_topic[key_industry[0]]\n",
    "            print(investors)\n",
    "        print(\"\\n\")\n",
    "        continue\n",
    "        print(\"\\n\" + filename_w_ext)\n",
    "        for kw in keywords:\n",
    "            print(str(kw[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDB(sectors_dir, investors_dir):\n",
    "    global db_investors_by_topic\n",
    "    global db_keyword_by_topic\n",
    "    list_files_sectors = get_list_of_files_from_folder(sectors_dir)\n",
    "    if len(list_files_sectors) == 0:\n",
    "        print(\"No Files found in sector folder \" + sectors_dir + \"\\n Exiting program\")\n",
    "        PrintHelp()\n",
    "        return\n",
    "    list_files_investors = get_list_of_files_from_folder(investors_dir)\n",
    "    if len(list_files_investors) == 0:\n",
    "        print(\"No Files found in investors folder \" + investors_dir + \"\\n Exiting program\")\n",
    "        PrintHelp()\n",
    "        return\n",
    "    for file_path in list_files_sectors:\n",
    "        filename_w_ext = os.path.basename(file_path)\n",
    "        file1 = open(file_path, 'r')\n",
    "        lines = file1.readlines()\n",
    "        sector_name = os.path.splitext(filename_w_ext)\n",
    "        for line in lines:\n",
    "            db_keyword_by_topic[line.strip().lower()] = sector_name[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for file_path in list_files_sectors:\n",
    "        filename_w_ext = os.path.basename(file_path)\n",
    "        file1 = open(file_path, 'r')\n",
    "        lines = file1.readlines()\n",
    "        sector_name = os.path.splitext(filename_w_ext)[0].strip()\n",
    "        for line in lines:\n",
    "            db_keyword_by_topic[line.strip().lower()] = sector_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for file_path in list_files_investors:\n",
    "        filename_w_ext = os.path.basename(file_path)\n",
    "        file1 = open(file_path, 'r', encoding=\"utf-8\", errors='ignore')\n",
    "        lines = file1.readlines()\n",
    "        sector_name = os.path.splitext(filename_w_ext)\n",
    "        for line in lines:\n",
    "            line = line.replace('\"', '')\n",
    "            split_test =  line.split(\",\")\n",
    "            if (len(split_test) < 3):\n",
    "                continue\n",
    "            for i in range(len(split_test)):\n",
    "                if i < 2 or len(split_test[0]) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    sector = split_test[i].lower().replace(\" \", \"\")\n",
    "                    if sector not in db_investors_by_topic:\n",
    "                        db_investors_by_topic[sector] = [split_test[0]]\n",
    "                    else:\n",
    "                        db_investors_by_topic[sector].append(split_test[0].strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
